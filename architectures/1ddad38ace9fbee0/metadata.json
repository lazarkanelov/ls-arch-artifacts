{
  "hash": "1ddad38ace9fbee0",
  "source_url": "https://github.com/aws-samples/deepseek-using-vllm-on-eks",
  "source_type": "github",
  "discovered_at": "2026-01-15T15:02:36.675144",
  "services": [
    "ecr"
  ],
  "resource_count": 2,
  "name": "deepseek-using-vllm-on-eks",
  "description": "",
  "version": null,
  "skipped": false,
  "skip_reason": null,
  "original_format": null,
  "terraform_files": {
    "helm.tf": "resource \"helm_release\" \"deepseek_gpu\" {\n  count            = var.enable_deep_seek_gpu ? 1 : 0\n  name             = \"deepseek-gpu\"\n  chart            = \"./vllm-chart\"\n  create_namespace = true\n  wait             = false\n  replace          = true\n  namespace        = \"deepseek\"\n\n  values = [\n    <<-EOT\n    nodeSelector:\n      owner: \"data-engineer\"\n      instanceType: \"gpu\"\n    tolerations:\n      - key: \"nvidia.com/gpu\"\n        operator: \"Exists\"\n        effect: \"NoSchedule\"\n    resources:\n      limits:\n        cpu: \"32\"\n        memory: 100G\n        nvidia.com/gpu: \"1\"\n      requests:\n        cpu: \"16\"\n        memory: 30G\n        nvidia.com/gpu: \"1\"\n    command: \"vllm serve deepseek-ai/DeepSeek-R1-Distill-Llama-8B --max_model 2048\"\n\n    livenessProbe:\n      httpGet:\n        path: /health\n        port: 8000\n      initialDelaySeconds: 1800\n      periodSeconds: 10\n\n    readinessProbe:\n      httpGet:\n        path: /health\n        port: 8000\n      initialDelaySeconds: 1800\n      periodSeconds: 5\n\n    EOT\n  ]\n  depends_on = [module.eks, kubernetes_manifest.gpu_nodepool]\n}\n\nresource \"helm_release\" \"deepseek_neuron\" {\n  count            = var.enable_deep_seek_neuron ? 1 : 0\n  name             = \"deepseek-neuron\"\n  chart            = \"./vllm-chart\"\n  create_namespace = true\n  wait             = false\n  replace          = true\n  namespace        = \"deepseek\"\n\n  values = [\n    <<-EOT\n    image:\n      repository: ${aws_ecr_repository.neuron-ecr.repository_url}\n      tag: 0.1\n      pullPolicy: IfNotPresent\n\n    nodeSelector:\n      owner: \"data-engineer\"\n      instanceType: \"neuron\"\n    tolerations:\n      - key: \"aws.amazon.com/neuron\"\n        operator: \"Exists\"\n        effect: \"NoSchedule\"\n\n    command: \"vllm serve deepseek-ai/DeepSeek-R1-Distill-Llama-8B --device neuron --tensor-parallel-size 2 --max-num-seqs 4 --block-size 8 --use-v2-block-manager --max-model-len 2048\"\n\n    env:\n      - name: NEURON_RT_NUM_CORES\n        value: \"2\"\n      - name: NEURON_RT_VISIBLE_CORES\n        value: \"0,1\"\n      - name: VLLM_LOGGING_LEVEL\n        value: \"INFO\"\n\n    resources:\n      limits:\n        cpu: \"30\"\n        memory: 64G\n        aws.amazon.com/neuron: \"1\"\n      requests:\n        cpu: \"30\"\n        memory: 64G\n        aws.amazon.com/neuron: \"1\"\n\n    livenessProbe:\n      httpGet:\n        path: /health\n        port: 8000\n      initialDelaySeconds: 1800\n      periodSeconds: 10\n\n    readinessProbe:\n      httpGet:\n        path: /health\n        port: 8000\n      initialDelaySeconds: 1800\n      periodSeconds: 5\n    EOT\n  ]\n  depends_on = [module.eks, kubernetes_manifest.neuron_nodepool]\n}\n",
    "main.tf": "variable \"enable_deep_seek_gpu\" {\n  description = \"Enable DeepSeek using GPUs\"\n  type        = bool\n  default     = false\n}\n\nvariable \"enable_deep_seek_neuron\" {\n  description = \"Enable DeepSeek using Neuron\"\n  type        = bool\n  default     = false\n}\n\nvariable \"enable_auto_mode_node_pool\" {\n  description = \"Enable EKS AutoMode NodePool\"\n  type        = bool\n  default     = false\n}\n\nlocals {\n  region   = \"us-east-1\"\n  vpc_cidr = \"10.0.0.0/16\"\n  name     = \"eks-automode\"\n  azs      = slice(data.aws_availability_zones.available.names, 0, 3)\n\n  tags = {\n    Blueprint = local.name\n  }\n}\n\n\n# Define the required providers\nprovider \"aws\" {\n  region = local.region # Change to your desired region\n}\n\nprovider \"kubernetes\" {\n  host                   = module.eks.cluster_endpoint\n  cluster_ca_certificate = base64decode(module.eks.cluster_certificate_authority_data)\n\n  exec {\n    api_version = \"client.authentication.k8s.io/v1beta1\"\n    command     = \"aws\"\n    # This requires the awscli to be installed locally where Terraform is executed\n    args = [\"eks\", \"get-token\", \"--cluster-name\", module.eks.cluster_name]\n  }\n}\n\nprovider \"helm\" {\n  kubernetes {\n    host                   = module.eks.cluster_endpoint\n    cluster_ca_certificate = base64decode(module.eks.cluster_certificate_authority_data)\n\n    exec {\n      api_version = \"client.authentication.k8s.io/v1beta1\"\n      command     = \"aws\"\n      # This requires the awscli to be installed locally where Terraform is executed\n      args = [\"eks\", \"get-token\", \"--cluster-name\", module.eks.cluster_name]\n    }\n  }\n}\n\ndata \"aws_availability_zones\" \"available\" {\n  # Do not include local zones\n  filter {\n    name   = \"opt-in-status\"\n    values = [\"opt-in-not-required\"]\n  }\n}\n\n# Use the Terraform VPC module to create a VPC\nmodule \"vpc\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"5.17.0\" # Use the latest version available\n\n  name = \"${local.name}-vpc\"\n  cidr = local.vpc_cidr\n\n  azs             = local.azs\n  private_subnets = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 4, k)]\n  public_subnets  = [for k, v in local.azs : cidrsubnet(local.vpc_cidr, 8, k + 48)]\n\n  enable_nat_gateway = true\n  single_nat_gateway = true\n\n  public_subnet_tags = {\n    \"kubernetes.io/role/elb\" = 1\n  }\n\n  private_subnet_tags = {\n    \"kubernetes.io/role/internal-elb\" = 1\n  }\n\n  tags = local.tags\n}\n\n# Use the Terraform EKS module to create an EKS cluster\nmodule \"eks\" {\n  source  = \"terraform-aws-modules/eks/aws\"\n  version = \"20.33.1\" # Use the latest version available\n\n  cluster_name    = local.name\n  cluster_version = \"1.31\" # Specify the EKS version you want to use\n\n  cluster_endpoint_public_access           = true\n  enable_irsa                              = true\n  enable_cluster_creator_admin_permissions = true\n\n  cluster_compute_config = {\n    enabled    = true\n    node_pools = [\"general-purpose\"]\n  }\n\n\n  vpc_id     = module.vpc.vpc_id\n  subnet_ids = module.vpc.private_subnets\n\n  tags = local.tags\n}\n\n\nresource \"aws_ecr_repository\" \"chatbot-ecr\" {\n  name                 = \"${local.name}-chatbot\"\n  image_tag_mutability = \"MUTABLE\"\n}\n\nresource \"aws_ecr_repository\" \"neuron-ecr\" {\n  name                 = \"${local.name}-neuron-base\"\n  image_tag_mutability = \"MUTABLE\"\n}\n\n# Outputs\noutput \"configure_kubectl\" {\n  description = \"Configure kubectl: make sure you're logged in with the correct AWS profile and run the following command to update your kubeconfig\"\n  value       = \"aws eks --region ${local.region} update-kubeconfig --name ${module.eks.cluster_name}\"\n}\n\noutput \"ecr_repository_uri\" {\n  value = aws_ecr_repository.chatbot-ecr.repository_url\n}\n\noutput \"ecr_repository_uri_neuron\" {\n  value = aws_ecr_repository.neuron-ecr.repository_url\n}",
    "nodepool_automode.tf": "resource \"kubernetes_manifest\" \"gpu_nodepool\" {\n  count = var.enable_auto_mode_node_pool && var.enable_deep_seek_gpu ? 1 : 0\n  manifest = {\n    apiVersion = \"karpenter.sh/v1\"\n    kind       = \"NodePool\"\n    metadata = {\n      name = \"gpu-nodepool\"\n    }\n    spec = {\n      template = {\n        metadata = {\n          labels = {\n            owner = \"data-engineer\"\n            instanceType = \"gpu\"\n          }\n        }\n        spec = {\n          nodeClassRef = {\n            group = \"eks.amazonaws.com\"\n            kind  = \"NodeClass\"\n            name  = \"default\"\n          }\n          taints = [\n            {\n              key    = \"nvidia.com/gpu\"\n              value  = \"Exists\"\n              effect = \"NoSchedule\"\n            }\n          ]\n          requirements = [\n            {\n              key      = \"eks.amazonaws.com/instance-family\"\n              operator = \"In\"\n              values   = [\"g5\", \"g6\", \"g6e\", \"p5\", \"p4\"]\n            },\n            {\n              key      = \"kubernetes.io/arch\"\n              operator = \"In\"\n              values   = [\"amd64\"]\n            },\n            {\n              key      = \"karpenter.sh/capacity-type\"\n              operator = \"In\"\n              values   = [\"spot\", \"on-demand\"]\n            }\n          ]\n        }\n      }\n      limits = {\n        cpu    = \"1000\"\n        memory = \"1000Gi\"\n      }\n    }\n  }\n\n  depends_on = [module.eks]\n}\n\nresource \"kubernetes_manifest\" \"neuron_nodepool\" {\n  count = var.enable_auto_mode_node_pool && var.enable_deep_seek_neuron ? 1 : 0\n  manifest = {\n    apiVersion = \"karpenter.sh/v1\"\n    kind       = \"NodePool\"\n    metadata = {\n      name = \"neuron-nodepool\"\n    }\n    spec = {\n      template = {\n        metadata = {\n          labels = {\n            owner = \"data-engineer\"\n            instanceType = \"neuron\"\n          }\n        }\n        spec = {\n          nodeClassRef = {\n            group = \"eks.amazonaws.com\"\n            kind  = \"NodeClass\"\n            name  = \"default\"\n          }\n          taints = [\n            {\n              key    = \"aws.amazon.com/neuron\"\n              value  = \"Exists\"\n              effect = \"NoSchedule\"\n            }\n          ]\n          requirements = [\n            {\n              key      = \"eks.amazonaws.com/instance-family\"\n              operator = \"In\"\n              values   = [\"inf2\"]\n            },\n            {\n              key      = \"karpenter.sh/capacity-type\"\n              operator = \"In\"\n              values   = [\"spot\", \"on-demand\"]\n            }\n          ]\n        }\n      }\n      limits = {\n        cpu    = \"1000\"\n        memory = \"1000Gi\"\n      }\n    }\n  }\n\n  depends_on = [module.eks]\n}"
  }
}